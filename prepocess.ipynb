{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T08:02:24.237018Z",
     "start_time": "2025-08-08T07:45:41.370182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, bz2, json, random, _pickle as pkl\n",
    "from pathlib import Path\n",
    "from typing   import Tuple, Iterator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "from skimage.measure import label, regionprops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ───────────────────────────── ПАРАМЕТРЫ ─────────────────────────────\n",
    "SEED          = 42          # фиксируем split\n",
    "TEST_RATIO    = 0.20        # 20 % исходников → test\n",
    "PATCH_SIZE    = (12, 256, 256)   # (Z, Y, X)!\n",
    "STRIDE        = (6, 256, 256)\n",
    "MAX_INST      = 20          # MAX_GT_INSTANCES в конфиге\n",
    "PICKLE_PROTO  = 4           # совместимо с Python 3.6\n",
    "GLOBAL_MAX    = 0\n",
    "SRC_IMG = Path(\"/NAS/mmaiurov/Datasets/Hela_MRC/images\")\n",
    "SRC_MSK = Path(\"/NAS/mmaiurov/Datasets/Hela_MRC/masks\")\n",
    "\n",
    "DST_ROOT = Path(\"/NAS/mmaiurov/Datasets/hela_mrc_patches256\")\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "# --- helpers ---------------------------------------------------------\n",
    "def extract_patches(vol: np.ndarray,\n",
    "                    ps: Tuple[int,int,int],\n",
    "                    st: Tuple[int,int,int]) -> Iterator[Tuple[np.ndarray,Tuple[int,int,int]]]:\n",
    "    dz, dy, dx = ps\n",
    "    sz, sy, sx = st\n",
    "    Z, Y, X    = vol.shape\n",
    "    for z0 in range(0, max(Z - dz + 1, 1), sz):\n",
    "        for y0 in range(0, max(Y - dy + 1, 1), sy):\n",
    "            for x0 in range(0, max(X - dx + 1, 1), sx):\n",
    "                patch = vol[z0:z0+dz, y0:y0+dy, x0:x0+dx]\n",
    "                if patch.shape == ps:\n",
    "                    yield patch, (z0, y0, x0)\n",
    "\n",
    "\n",
    "def instance_masks_from_semantic(seg_patch: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"seg_patch: uint16 (0=фон, >0=класс).  Возвращает bool [Z,Y,X,N].\"\"\"\n",
    "    conn = label(seg_patch > 0, connectivity=1)\n",
    "    labels = np.unique(conn)\n",
    "    labels = labels[labels != 0][:MAX_INST]\n",
    "    if labels.size == 0:\n",
    "        return np.zeros(seg_patch.shape + (0,), dtype=np.uint8)\n",
    "    masks = np.zeros(seg_patch.shape + (labels.size,), dtype=np.uint8)\n",
    "    for k, lbl in enumerate(labels):\n",
    "        masks[..., k] = (conn == lbl)\n",
    "    return masks\n",
    "\n",
    "\n",
    "def bboxes_from_masks(masks: np.ndarray) -> list[str]:\n",
    "    \"\"\"masks[...,N] → строки 'class z0 y0 x0 z1 y1 x1' (class=1).\"\"\"\n",
    "    if masks.size == 0:\n",
    "        return []\n",
    "    lines = []\n",
    "    for k in range(masks.shape[-1]):\n",
    "        coords = regionprops(masks[..., k])[0].bbox  # z0,y0,x0,z1,y1,x1\n",
    "        z0,y0,x0,z1,y1,x1 = coords\n",
    "        if z1>z0 and y1>y0 and x1>x0:\n",
    "            lines.append(f\"1 {z0} {y0} {x0} {z1} {y1} {x1}\")\n",
    "    return lines\n",
    "\n",
    "\n",
    "def save_pickle(arr: np.ndarray, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with bz2.BZ2File(str(path.with_suffix('.pickle')), \"wb\") as fh:\n",
    "        pkl.dump(arr, fh, protocol=PICKLE_PROTO)\n",
    "\n",
    "\n",
    "def write_csv(rows: list[dict], dst: Path):\n",
    "    dst.parent.mkdir(exist_ok=True)\n",
    "    pd.DataFrame(rows).to_csv(dst, index=False)\n",
    "\n",
    "\n",
    "# --- train / test split ---------------------------------------------\n",
    "img_files = sorted(SRC_IMG.glob(\"*.tif\"))\n",
    "msk_files = sorted(SRC_MSK.glob(\"*.tif\"))\n",
    "assert len(img_files) == len(msk_files) > 0, \"Не найдены парные TIF-ы\"\n",
    "\n",
    "pairs = list(zip(img_files, msk_files))\n",
    "random.seed(SEED)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "split_idx      = int(len(pairs) * (1 - TEST_RATIO))\n",
    "split_to_pairs = {\"train\": pairs[:split_idx],\n",
    "                  \"test\":  pairs[split_idx:]}\n",
    "\n",
    "print(f\"Исходных томов: train={len(split_to_pairs['train'])}, test={len(split_to_pairs['test'])}\")\n",
    "\n",
    "# --- основной цикл ---------------------------------------------------\n",
    "for split, pairs in split_to_pairs.items():\n",
    "    img_out  = DST_ROOT / split / \"images\"\n",
    "    seg_out  = DST_ROOT / split / \"seg\"\n",
    "    cab_out  = DST_ROOT / split / \"classes_and_boxes\"\n",
    "    ipkl_out = DST_ROOT / split / \"img_pickle\"\n",
    "    mpkl_out = DST_ROOT / split / \"masks\"\n",
    "\n",
    "    for p in (img_out, seg_out, cab_out, ipkl_out, mpkl_out):\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    csv_rows = []\n",
    "\n",
    "    for img_path, msk_path in tqdm(pairs, desc=f\"{split}: патчи\"):\n",
    "        base_name = img_path.stem           # без .tif\n",
    "        img_vol   = tiff.imread(img_path)\n",
    "        msk_vol   = tiff.imread(msk_path)\n",
    "\n",
    "        for idx, ((i_patch,_), (s_patch,_)) in enumerate(\n",
    "                zip(extract_patches(img_vol, PATCH_SIZE, STRIDE),\n",
    "                    extract_patches(msk_vol, PATCH_SIZE, STRIDE))):\n",
    "\n",
    "            p_tag = f\"{base_name}_p{idx:04d}\"\n",
    "            # --- save raw tiff (для отладки) --------------------------\n",
    "            tiff.imwrite(img_out / f\"{p_tag}_image.tiff\", i_patch, dtype=img_vol.dtype)\n",
    "            tiff.imwrite(seg_out / f\"{p_tag}_seg.tiff\",   s_patch, dtype=msk_vol.dtype)\n",
    "\n",
    "            # --- pickle image ----------------------------------------\n",
    "            img_float = 2 * (i_patch.astype(np.float32) / 255.) - 1.\n",
    "            save_pickle(img_float, ipkl_out / f\"{p_tag}_image\")\n",
    "\n",
    "            # --- instance masks & pickle -----------------------------\n",
    "            m_inst = instance_masks_from_semantic(s_patch)\n",
    "            inst_cnt = m_inst.shape[-1]\n",
    "            if inst_cnt > GLOBAL_MAX:\n",
    "                GLOBAL_MAX = inst_cnt\n",
    "            save_pickle(m_inst, mpkl_out / f\"{p_tag}_seg\")\n",
    "\n",
    "            # --- classes_and_boxes (.dat) ----------------------------\n",
    "            lines = bboxes_from_masks(m_inst)\n",
    "            for suff in (\"_seg.dat\", \"_image.dat\"):\n",
    "                (cab_out / f\"{p_tag}{suff}\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "            # --- row for CSV -----------------------------------------\n",
    "            csv_rows.append({\n",
    "                \"names\":  p_tag,\n",
    "                \"images\": str(ipkl_out / f\"{p_tag}_image.pickle\"),\n",
    "                \"segs\":   str(seg_out  / f\"{p_tag}_seg.tiff\"),\n",
    "                \"cabs\":   str(cab_out  / f\"{p_tag}_image.dat\"),\n",
    "                \"masks\":  str(mpkl_out / f\"{p_tag}_seg.pickle\")\n",
    "            })\n",
    "\n",
    "    write_csv(csv_rows, DST_ROOT / \"datasets\" / f\"{split}.csv\")\n",
    "    print(f\"✓ {split}.csv   ({len(csv_rows)} патчей)\")\n",
    "\n",
    "print(\"Готово — все патчи, pickle и CSV созданы.\")\n",
    "print(f\"\\n★ Максимум объектов в одном патче = {GLOBAL_MAX}\")\n"
   ],
   "id": "9e78828dbdea16c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходных томов: train=4, test=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: патчи: 100%|██████████| 4/4 [12:43<00:00, 190.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ train.csv   (2176 патчей)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: патчи: 100%|██████████| 2/2 [03:59<00:00, 119.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ test.csv   (896 патчей)\n",
      "Готово — все патчи, pickle и CSV созданы.\n",
      "\n",
      "★ Максимум объектов в одном патче = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T08:04:57.180308Z",
     "start_time": "2025-08-08T08:04:56.931870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DST_ROOT = Path(\"/NAS/mmaiurov/Datasets/hela_mrc_patches256\")\n",
    "OUT_DIR = DST_ROOT / \"datasets\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    img_dir = DST_ROOT / split / \"images\"\n",
    "    cab_dir = DST_ROOT / split / \"classes_and_boxes\"\n",
    "    mask_dir = DST_ROOT / split / \"masks\"\n",
    "\n",
    "    rows = []\n",
    "    for tiff_path in sorted(img_dir.glob(\"*_image.tiff\")):\n",
    "        base = tiff_path.name.replace(\"_image.tiff\", \"\")\n",
    "        row = {\n",
    "            \"names\":  f\"/NAS/mmaiurov/Datasets/hela_mrc_patches256/{split}/images/{base}_image.tiff\",\n",
    "            \"images\": f\"/NAS/mmaiurov/Datasets/hela_mrc_patches256/{split}/images/{base}_image.tiff\",\n",
    "            \"segs\":   f\"/NAS/mmaiurov/Datasets/hela_mrc_patches256/{split}/images/{base}_seg.tiff\",\n",
    "            \"cabs\":   f\"/NAS/mmaiurov/Datasets/hela_mrc_patches256/{split}/classes_and_boxes/{base}_image.dat\",\n",
    "            \"masks\":  f\"/NAS/mmaiurov/Datasets/hela_mrc_patches256/{split}/masks/{base}_seg.pickle\"\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(OUT_DIR / f\"{split}.csv\", index=False)\n",
    "    print(f\"✓ Создано: {split}.csv ({len(rows)} строк)\")"
   ],
   "id": "83d12bd2f3d386ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Создано: train.csv (2176 строк)\n",
      "✓ Создано: test.csv (896 строк)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7565466a96589514"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
